## 题目1

### Tensorflow

1. 模型：借鉴VGGNet的设计，但由于数据集像素较小，对网络做了部分删减和改进，卷积核大小均为3\*3，stride=1, padding=1, 各层输出为
	- Conv1: (batch_size, 28, 28, 64), Relu
	- Conv2: (batch_size, 28, 28, 64), Relu
	- Maxpooling: (batch_size, 14, 14, 64)
	- Conv1: (batch_size, 14, 14, 128), Relu
	- Conv2: (batch_size, 14, 14, 128), Relu
	- Maxpooling: (batch_size, 7, 7, 128)
	- Conv1: (batch_size, 7, 7, 256), Relu
	- Conv2: (batch_size, 7, 7, 256), Relu
	- Avgpooling: (batch_size, 1, 1, 256)(Global Average Pooling)
	- Linear: (batchsize, 10)
2. 数据：采用Tensorflow自带的mnist的数据处理对fashion mnist数据集做预处理
3. 超参：优化方法采用Adam, 初始学习率为0.001
4. 结果：batchsize选择200，训练20000次，测试集上最优准确率为0.9305


### PyTorch

1. 模型：刚接触Tensorflow，模型很多地方还不会调整，同样的模型放在PyTorch中，做了些小改动，效果更好
	- 每个Conv层后添加Batch Normalization层
	- 全局池化改为全连接层，fc1为(256\*7\*7, 2048), relu, dropout(0.5)输出送入softmax层
2. 数据：添加随机水平翻转
3. 超参：优化方法采用Adam, 初始学习率为0.001
4. 结果：batchsize选择128，epochs为50，测试集上最优准确率为0.9439
